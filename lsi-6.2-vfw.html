<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>LSI Section 6 VFW</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Book Club Notes</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Posts</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">LSI Section 6 VFW</h1>

</div>


<div id="modified-central-matching-estimation-for-the-empirical-null" class="section level2">
<h2>Modified Central Matching Estimation for the Empirical Null</h2>
<p>Review the central matching estimation for the empirical null described in Efron section 6.2, an example with the HIV<!-- and simulated data -->, and a modified version of the central matching approach that constrains the empirical null mean to be equal to 0.</p>
<div id="central-matching-estimation-of-delta_0-sigma_0-pi_0" class="section level3">
<h3>Central Matching Estimation of <span class="math inline">\((\delta_0, \sigma_0, \pi_0)\)</span></h3>
<p>Define <span class="math inline">\(f_{\pi 0}(z) = \pi_0 f_0(z)\)</span> so that <span class="math inline">\(fdr(z) = f_{\pi 0}(z)/f(z)\)</span>. We assume that <span class="math inline">\(f_0(z)\)</span> is normal but not necessarily <span class="math inline">\(N(0, 1)\)</span>, say <span class="math inline">\(f_0(z) \sim N(\delta_0, \sigma_0^2)\)</span> (Efron, p. 98).</p>
<p>Therefore, the <span class="math inline">\(f_{\pi 0}(z)\)</span> is estimated by</p>
<span class="math display">\[\begin{align}
f_{\pi 0}(z) &amp; = \pi_0 f_0(z) \\
&amp; = \pi_0 \cdot \left[ \frac{1}{\sqrt{2 \pi \sigma_0^2}} \exp \left[ \frac{-1}{2 \sigma_0^2} (z - \delta_0^2) \right] \right] \\
&amp; = \pi_0 \cdot (2 \pi \sigma_0^2)^{-1/2} \cdot \exp \left[-\frac{1}{2} \left( \frac{z^2}{\sigma_0^2} - \frac{2 z \delta_0}{\sigma_0^2} + \frac{\delta_0^2}{\sigma_0^2} \right)  \right] \\
&amp; \text {and} \\
\log (f_{\pi 0}(z)) &amp; = \log (\pi_0) - \frac{1}{2} \log(2 \pi \sigma_0^2) + \left[-\frac{1}{2} \left( \frac{1}{\sigma_0^2} z^2 - \frac{2 \delta_0}{\sigma_0^2} z  + \frac{\delta_0^2}{\sigma_0^2} \right)  \right] \\
&amp; = \left[\log(\pi_0) - \frac{1}{2} \left( \log(2\pi \sigma_0^2) + \frac{\delta_0^2}{\sigma_0^2 } \right) \right] + \frac{\delta_0}{\sigma_0^2} z - \frac{1}{2\sigma_0^2} z^2.
\end{align}\]</span>
<p>Notice that this is a quadratic form. In the central matching approach (as well as in the MLE approach) we make the “zero assumption”, in assuming that the mixture distribution <span class="math inline">\(f(z)\)</span> is equal to <span class="math inline">\(\pi_0 f_0(z)\)</span> near <span class="math inline">\(z=0\)</span> (i.e. for <span class="math inline">\(z \in \mathscr{A}_0\)</span>). This is a result of the assumption that <span class="math inline">\(f_1(z)\)</span> is equal to zero within the middle <span class="math inline">\(\mathscr{A}_0\)</span> proportion of the mixture distribution, i.e.</p>
<span class="math display">\[\begin{align}
f(z) &amp; = \pi_0 f_0(z) + (1-\pi_0) \cdot 0 \\
&amp; = \pi_0 f_0(z) \\
&amp; = f_{\pi 0}(z)
\end{align}\]</span>
<p>for <span class="math inline">\(z \in \mathscr{A}_0\)</span>. Therefore, because we assume <span class="math inline">\(\log(f(z)) = \log(f_{\pi 0}(z))\)</span> and we observed above that <span class="math inline">\(\log(f_{\pi 0}(z))\)</span> is quadratic, the key assumption of the central matching approach can be stated as</p>
<span class="math display">\[\begin{align}
\log(f(z)) = \log(f_{\pi 0}(z)) = \beta_0 + \beta_1 z + \beta_2 z^2 \\
\end{align}\]</span>
<p>for <span class="math inline">\(z \in \mathscr{A}_0\)</span>, where</p>
<span class="math display">\[\begin{align}
\beta_0 &amp; = \log(\pi_0) - \frac{1}{2} \left( \log(2\pi \sigma_0^2) + \frac{\delta_0^2}{\sigma_0^2 } \right) \\
\beta_1 &amp; = \frac{\delta_0}{\sigma_0^2} \\
\beta_2 &amp; = - \frac{1}{2\sigma_0^2}. \\
\end{align}\]</span>
<p>The coefficients <span class="math inline">\((\beta_0, \beta_1, \beta_2)\)</span> are estimated via Lindsey’s method, with a <span class="math inline">\(J=2\)</span> parameter family, using only the central <span class="math inline">\(\mathscr{A}_0\)</span> proportion of <span class="math inline">\(z_i\)</span> values. More specifically, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are estimated from the Poisson regression process, and <span class="math inline">\(\beta_0\)</span> is determined from the requirement that <span class="math inline">\(f(z)\)</span> integrates to 1. That is,</p>
<span class="math display">\[\begin{align}
\beta_0 &amp; : \\
&amp; \int f(z) dz = 1 \\
&amp; \int \exp (\beta_0 + \beta_1 z + \beta_2 z^2) dz = 1 \\
&amp; ... \\
&amp; ... 
\end{align}\]</span>
<p>Recall that, briefly, Lindsey’s method is an algorithm based on discretizing the <span class="math inline">\(z_i\)</span> values into <span class="math inline">\(K\)</span> bins and it obtains maximum likelihood estimates for <span class="math inline">\((\beta_1, \beta_2)\)</span> by fitting the observed number of values in each [histogram] bin (<span class="math inline">\(y_k\)</span>) against the midpoint of each bin (<span class="math inline">\(x_k\)</span>) via a Poisson regression (Section 5.2, p. 75). Note that <span class="math inline">\(K\)</span> and <span class="math inline">\(\mathscr{A}_0\)</span> are tuning parameters of this method. The coefficients <span class="math inline">\((\delta_0, \sigma_0, \pi_0)\)</span> are then given by</p>
<span class="math display">\[\begin{align}
\sigma_0 &amp; = \sqrt{-\frac{1}{2 \beta_2}} \\
\delta_0 &amp; = \beta_1 \sigma_0^2 \\
&amp; = \beta_1 \left( -\frac{1}{2 \beta_2} \right) \\
\pi_0 &amp; = \exp \left[\beta_0 + \frac{1}{2} \left( \log (2\pi \sigma_0^2) + \frac{\delta_0^2}{\sigma_0^2}  \right)  \right] \\
&amp; = \exp \left[\beta_0 + \frac{1}{2} \left( \log (2\pi \sigma_0^2) + \frac{\beta_1^2 \sigma_0^4}{\sigma_0^2}  \right)  \right] \\
&amp; = \exp \left[\beta_0 + \frac{1}{2} \left( \log (2\pi \sigma_0^2) + \beta_1^2 \sigma_0^2  \right)  \right] \\
&amp; = \exp \left[\beta_0 + \frac{1}{2} \left( \log \left(2\pi \left( -\frac{1}{2 \beta_2} \right) \right) + \beta_1^2 \left( -\frac{1}{2 \beta_2} \right) \right)  \right] \\
&amp; = \exp \left[ \beta_0 + \frac{1}{2} \left( \log (-\pi) - \log (\beta_2) - \frac{\beta_1^2}{2 \beta_2} \right) \right]
\end{align}\]</span>
<!-- 
**Question: while in section 6.2, Efron makes references to the notation used in section 5.2 (i.e. "estimating $(\beta_0, \beta_2, \beta_3)$ from the histogram counts $y_k$ (5.12) around $z=0$" and "The quadratic approximation $\log \widehat{f}_{\pi 0}(z) = \widehat{\beta}_0 + \widehat{\beta}_1 z + \widehat{\beta}_2 z^2$ was computed as the least square fit to $\log \widehat{f}(z)$ over the central 50% of the $z$-values (with the calculation discretized as in section 5.2)"), it is not 100% clear whether we actually use Lindsey's method, or whether we use some other least squares fit approach (not a Poisson model fit) although the discretization used in the approach is the same as in 5.2?
-->
<pre class="r"><code>library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>library(locfdr)

zz = get(data(hivdata)) ## z-scores ## length = 7,680
  hist(zz, breaks = 100)</code></pre>
<p><img src="lsi-6.2-vfw_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>pct = 0 # &lt;- default ## excluded tail proportion of z-scores when fitting f(z)
pct0 = 1/4 # &lt;- default ## proportion of z-score distr used in fitting null density by central matching; if vector, provides lower and upper tail cutoffs, and if scalar, provides lower tail cutoff


## one attempted adjustment - still doesn&#39;t match
# zz = zz[which(zz &gt; -4.1 &amp; zz &lt; 4.1)]
# hist(zz, breaks = 100)

## another attempted adjustment
zz = -zz

## another attempted adjustment: (combined with above seems to work)
zz[which(zz &lt;= -4.1)] = -4.1
zz[which(zz &gt;= 4.1)] = 4.1
hist(zz, breaks = 100)</code></pre>
<p><img src="lsi-6.2-vfw_files/figure-html/unnamed-chunk-1-2.png" width="672" /></p>
<pre class="r"><code>### re-calculate z-statistics
# hiv_raw = log(get(load(file.path(&#39;/Users/valeriewelty/Dropbox/Vandy/SEDS Lab Group/SEDSLab/LSI Book/Data and Programs&#39;, &#39;hivdata.Rda&#39;))), base = exp(1))
# tt = apply(hiv_raw, 1, FUN=function(x) t.test(x[1:4], x[5:8], var.equal = TRUE)$statistic)
# pp = pt(tt, df = 6)
# # pp = apply(hiv_raw, 1, FUN=function(x) t.test(x[1:4], x[5:8], var.equal = TRUE)$p.value)
# zz = qnorm(pp)
# hist(zz, breaks = 100)

## one attempted adjustment: 
# zz = zz[which(zz &gt; -4.1 &amp; zz &lt; 4.1)]
# hist(zz, breaks = 100)

## another attempted adjustment:
# zz[which(zz &lt;= -4.1)] = -4.1
# zz[which(zz &gt;= 4.1)] = 4.1
# hist(zz, breaks = 100)</code></pre>
<pre class="r"><code># p. 75
K = 90
d = 0.1
J = 7
breaks = seq(-4.5, 4.5, d)
length(breaks)-1 == K</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>results=locfdr(zz=zz, bre=K, df=J, pct=pct, pct0=pct0, nulltype=2, type=1)</code></pre>
<p><img src="lsi-6.2-vfw_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>  # nulltype = 2 uses central matching in fitting f0(z)
  # type = 0 uses ns in fitting f(z)
results$fp0</code></pre>
<pre><code>##            delta      sigma          p0
## thest 0.00000000 1.00000000 1.195015162
## theSD 0.00000000 0.00000000 0.010907285
## mlest 0.11597111 0.75373650 0.934174674
## mleSD 0.01228385 0.01483100 0.008933865
## cmest 0.12295193 0.75826229 0.928265602
## cmeSD 0.01532833 0.01232761 0.006680987</code></pre>
<pre class="r"><code>alpha = (1-pct0)-pct0
zz_alpha = sort(zz)[(pct0*length(zz)):((1-pct0)*length(zz))]
  length(zz_alpha)/length(zz)</code></pre>
<pre><code>## [1] 0.5001302</code></pre>
<pre class="r"><code>h = hist(zz_alpha, breaks=breaks, plot=F)

# Lindsey&#39;s method
Zk = h$breaks
yk = h$counts
xk = h$mids

fit = glm(yk ~ poly(xk, J, raw=F), family=&quot;poisson&quot;)</code></pre>
<pre><code>## Warning: glm.fit: fitted rates numerically 0 occurred</code></pre>
<pre class="r"><code># fit = glm(yk ~ poly(xk, 2, raw=T), family=&quot;poisson&quot;)
# fit = glm(yk ~ poly(xk, J, raw=T), family=&quot;poisson&quot;)
# fit = glm(yk ~ splines::ns(xk, df=J), family=&quot;poisson&quot;)

beta1 = fit$coefficients[2]
beta2 = fit$coefficients[3]
beta0 = NULL

( delta0 = beta1*(-1/(2*beta2)) )</code></pre>
<pre><code>## poly(xk, J, raw = F)1 
##            -0.4336487</code></pre>
<pre class="r"><code>( sigma0 = sqrt(-1/(2*beta2)) )</code></pre>
<pre><code>## poly(xk, J, raw = F)2 
##          0.0004233156</code></pre>
<pre class="r"><code>( pi0 = NULL )</code></pre>
<pre><code>## NULL</code></pre>
<!-- 
### Central Matching Estimation for $\delta_0 = 0$

Now, we take a similar approach but instead we require that the null distribution have mean 0, while allowing the variance to differ, i.e. let $f_0(z) \sim N(0, \sigma_0^2)$. 
-->
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
